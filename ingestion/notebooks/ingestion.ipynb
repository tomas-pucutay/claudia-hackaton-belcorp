{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8CD1UdFmhuZ"
      },
      "source": [
        "**INGESTION**: Download videos from Belcorp Youtube Channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qtjjO6imeek"
      },
      "outputs": [],
      "source": [
        "# Util step if you run this in a Google Colab to test as we did\n",
        "# !pip install youtube-search-python yt-dlp openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8fQE-1-Fm_df"
      },
      "outputs": [],
      "source": [
        "BASE_YOUTUBE_PLAYLIST_URL = \"https://www.youtube.com/playlist?list=\"\n",
        "playlist_id = \"PLxF7HdNkCOLTELPKp_nSyEduDJoIbXNG-\" #Minuto acadÃ©mico: Info de productos\n",
        "# playlist_id = \"PLxF7HdNkCOLQOAOmQsR3I0I76qklNZucW\" #Herramientas digitales: Tecnicas de venta\n",
        "# playlist_id = \"PLxF7HdNkCOLRCoOL4jTdLWV7nJPHXJyCI\" #Lanzamientos: Info de productos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s8mVbjK7nRTp"
      },
      "outputs": [],
      "source": [
        "from youtubesearchpython import *\n",
        "from typing import List, Dict\n",
        "import yt_dlp\n",
        "import whisper\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u88_alQNnXOB"
      },
      "outputs": [],
      "source": [
        "def get_new_videos(playlist_id: str) -> List:\n",
        "    \"\"\"\n",
        "    Get all the videos from the specified playlist.\n",
        "    Return an array of dictionaries, every dictionary is a video.\n",
        "    The information from each video is selected from id, title, link and thumbnail keys\n",
        "    - playlist_id: str > ID in a youtube playlist\n",
        "    \"\"\"\n",
        "    \n",
        "    playlist = Playlist(f'{BASE_YOUTUBE_PLAYLIST_URL}{playlist_id}')\n",
        "    while playlist.hasMoreVideos:\n",
        "        print('Getting more videos...')\n",
        "        playlist.getNextVideos()\n",
        "        print(f'Videos Retrieved: {len(playlist.videos)}')\n",
        "    \n",
        "    print(\"Total number of videos: \", len(playlist.videos))\n",
        "\n",
        "    videos = [video for video in playlist.videos]\n",
        "\n",
        "    new_videos = []\n",
        "    for video in videos:\n",
        "        video_id = video.get('id')\n",
        "        video_title = video.get('title')\n",
        "        video_url = video.get('link')\n",
        "        video_thumbnail = video.get('thumbnails')[0].get('url')\n",
        "        new_video = {\"id\": video_id,\n",
        "                     \"title\": video_title,\n",
        "                     \"url\": video_url, \n",
        "                     \"thumbnail\": video_thumbnail,\n",
        "                    }\n",
        "        new_videos.append(new_video)\n",
        "    return new_videos\n",
        "\n",
        "def save_audio(video: Dict):\n",
        "    \"\"\"\n",
        "    It uses yt_dlp to save the audio from the url of an individual video.\n",
        "    - video: Dict > Video in a dictionary format to extract the url and id\n",
        "    \"\"\"\n",
        "    video_id = video.get('id')\n",
        "    video_url = video.get('url')\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': f'audio/{video_id}.m4a',\n",
        "        'noplaylist': True,\n",
        "        'postprocessors': [{  \n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'm4a',\n",
        "        }]}\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        result = ydl.download(video_url)\n",
        "    return result\n",
        "\n",
        "def get_audio(videos: List) -> Dict:\n",
        "    \"\"\"\n",
        "    From a list of videos, saves the audio from each one.\n",
        "    And also adds some values that are necessary to match the work already done\n",
        "    - videos: List > List of videos, each one as a dictionary with relevant keys.\n",
        "    \"\"\"\n",
        "    new_videos = []\n",
        "    for video in videos:\n",
        "        try:\n",
        "            result = save_audio(video)\n",
        "            video_id = video.get('id')\n",
        "            video_location = f'audio/{video_id}.m4a'\n",
        "            \n",
        "            if(result != 0):\n",
        "                print(\"Error downloading audio for video:\", video_id)\n",
        "                continue\n",
        "            \n",
        "            new_video = video.copy()\n",
        "            new_video[\"audio\"] = video_location\n",
        "            new_video[\"transcription\"] = \"NA\"\n",
        "            new_video[\"transcribed\"] = False\n",
        "            new_video[\"processed\"] = False\n",
        "            new_videos.append(new_video)\n",
        "        except Exception as e:\n",
        "            video_title = video.get('title')\n",
        "            print(\"Error downloading audio for episode:\", video_title, e)\n",
        "    return new_videos\n",
        "\n",
        "def save_new_videos(new_videos: List, existing_videos: List):\n",
        "    \"\"\"\n",
        "    Makes a videos.json file and save the satus of each audio download.\n",
        "    It prevents to do the same work in the future it its already done.\n",
        "    - new_videos: List > New videos that will be processed.\n",
        "    - existing_videos: List > Videos already processed.\n",
        "    \"\"\"\n",
        "    with open('videos.json', 'w') as f:\n",
        "        f.write(json.dumps(existing_videos + new_videos))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Main function for ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "twhKCRiKnuVb"
      },
      "outputs": [],
      "source": [
        "def start_audio_download():\n",
        "    \"\"\"\n",
        "    Entry point to start downloading youtube videos and saving the audio\n",
        "    \"\"\"\n",
        "    existing_videos = []\n",
        "    try:\n",
        "        with open('videos.json', 'r') as f:\n",
        "            existing_videos = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(\"Exception when opening file\", e)\n",
        "    videos = get_new_videos(playlist_id)\n",
        "    existing_videos_id = [video.get('id') for video in existing_videos]\n",
        "    filtered_videos = [video for video in videos if video.get('id') not in existing_videos_id]\n",
        "    new_videos = get_audio(filtered_videos)\n",
        "    save_new_videos(new_videos, existing_videos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd6l1binpzBc"
      },
      "source": [
        "**INGESTION**: Audio transcription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jZY--kOhqIZg"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(path: str):\n",
        "    \"\"\"\n",
        "    Runs whisper model for the audio file sent in the path argument.\n",
        "    - path: str > Location of the specific m4a audio file.\n",
        "    \"\"\"\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(path)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qfcAgEcLc2f_"
      },
      "outputs": [],
      "source": [
        "def format_transcription(transcription: str):\n",
        "    \"\"\"\n",
        "    Format a transcription as a list of segments with metadata\n",
        "    - transcription: str > Text of transcription from a video\n",
        "    \"\"\"\n",
        "    formatted_segments = []\n",
        "    for segment in transcription['segments']:\n",
        "        formatted_segment = {\n",
        "            'start': segment['start'],\n",
        "            'end': segment['end'],\n",
        "            'text': segment['text']}\n",
        "        formatted_segments.append(formatted_segment)\n",
        "    return formatted_segments\n",
        "\n",
        "def save_transcription(transcription: List, filename: str, directory: str = \"transcriptions\"):\n",
        "    \"\"\"\n",
        "    Save the formatted transcription in directory\n",
        "    - transcription: List > List of segments from transcription\n",
        "    - filename: str > Name for the output file.\n",
        "    - directory: str > Place where it will be located.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    with open(f'{directory}/{filename}', 'w') as f:\n",
        "        f.write(json.dumps(transcription))\n",
        "    print(\"Transcription saved\")\n",
        "\n",
        "def save_updated_videos(videos: List, filename: str = \"videos.json\"):\n",
        "    \"\"\"\n",
        "    Update the keys from the videos.json related to transcript flag\n",
        "    - videos: List > List of videos transcripted.\n",
        "    - filename: str > Name for output in json file.\n",
        "    \"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(json.dumps(videos))\n",
        "    print(\"Updated videos saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pcut4rWTqLyj"
      },
      "outputs": [],
      "source": [
        "def start_audio_transcription():\n",
        "    \"\"\"\n",
        "    Entry point to transcribe the audio downloaded in the previous step\n",
        "    It will get the location of the audio files from videos.json file\n",
        "    \"\"\"\n",
        "    print(\"Starting\")\n",
        "    directory = \"transcriptions\"\n",
        "    with open('videos.json', 'r') as f:\n",
        "        videos = json.load(f)\n",
        "        if(len(videos) == 0):\n",
        "            print(\"No videos to transcribe\")\n",
        "            pass\n",
        "        for video in videos:\n",
        "            if video['processed'] == True or video['transcribed'] == True:\n",
        "                print(\"Video already transcribed or processed\")\n",
        "                continue\n",
        "            audio_path = video['audio']\n",
        "            filename = video['title'].replace(\" \", \"_\").replace(\"/\",\"_\") + \".json\"\n",
        "            transcription = transcribe_audio(audio_path)\n",
        "            formatted_transcription = format_transcription(transcription)\n",
        "            save_transcription(formatted_transcription, filename, directory)\n",
        "            video['transcription'] = f'{directory}/{filename}'\n",
        "            video['transcribed'] = True\n",
        "            save_updated_videos(videos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run full download and transcriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j5C0gfuXqG5"
      },
      "outputs": [],
      "source": [
        "start_audio_download()\n",
        "start_audio_transcription()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
